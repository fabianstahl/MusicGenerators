% == Midi based ==

% 81
@article{yang2017midinet,
  title={MidiNet: A convolutional generative adversarial network for symbolic-domain music generation},
  author={Yang, Li-Chia and Chou, Szu-Yu and Yang, Yi-Hsuan},
  journal={arXiv preprint arXiv:1703.10847},
  year={2017}
}


% 32
@article{roberts2018hierarchical,
  title={A hierarchical latent vector model for learning long-term structure in music},
  author={Roberts, Adam and Engel, Jesse and Raffel, Colin and Hawthorne, Curtis and Eck, Douglas},
  journal={arXiv preprint arXiv:1803.05428},
  year={2018}
}

% 7
@article{tikhonov2017music,
  title={Music generation with variational recurrent autoencoder supported by history},
  author={Tikhonov, Alexey and Yamshchikov, Ivan P},
  journal={arXiv preprint arXiv:1705.05458},
  year={2017}
}


% 6
@article{hennig2017classifying,
  title={A classifying variational autoencoder with application to polyphonic music generation},
  author={Hennig, Jay A and Umakantha, Akash and Williamson, Ryan C},
  journal={arXiv preprint arXiv:1711.07050},
  year={2017}
}


% == Sound based ==

% wavenet
@article{van2016wavenet,
  title={WaveNet: A generative model for raw audio.},
  author={Van Den Oord, A{\"a}ron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew W and Kavukcuoglu, Koray},
  journal={SSW},
  volume={125},
  year={2016}
}

% 21 (eher Autoencoder)
@inproceedings{roberts2017hierarchical,
  title={Hierarchical variational autoencoders for music},
  author={Roberts, Adam and Engel, Jesse and Eck, Douglas},
  booktitle={NIPS Workshop on Machine Learning for Creativity and Design},
  year={2017}
}

% 59 (BUCH!)
@article{briot2017deep,
  title={Deep learning techniques for music generation-a survey},
  author={Briot, Jean-Pierre and Hadjeres, Ga{\"e}tan and Pachet, Fran{\c{c}}ois},
  journal={arXiv preprint arXiv:1709.01620},
  year={2017}
}


@inproceedings{colonel2017improving,
  title={Improving neural net auto encoders for music synthesis},
  author={Colonel, Joseph and Curro, Christopher and Keene, Sam},
  booktitle={Audio Engineering Society Convention 143},
  year={2017},
  organization={Audio Engineering Society}
}


@inproceedings{eppe2018towards,
  title={Towards End-to-End Raw Audio Music Synthesis},
  author={Eppe, Manfred and Alpay, Tayfun and Wermter, Stefan},
  booktitle={International Conference on Artificial Neural Networks},
  pages={137--146},
  year={2018},
  organization={Springer}
}

% 22 WaveGAN!
@article{donahue2018adversarial,
  title={Adversarial audio synthesis},
  author={Donahue, Chris and McAuley, Julian and Puckette, Miller},
  journal={arXiv preprint arXiv:1802.04208},
  year={2018}
}


%3 SynthGAN
@article{engel2019gansynth,
  title={Gansynth: Adversarial neural audio synthesis},
  author={Engel, Jesse and Agrawal, Kumar Krishna and Chen, Shuo and Gulrajani, Ishaan and Donahue, Chris and Roberts, Adam},
  journal={arXiv preprint arXiv:1902.08710},
  year={2019}
}

% 21
@inproceedings{sarroff2014musical,
  title={Musical audio synthesis using autoencoding neural nets},
  author={Sarroff, Andy M and Casey, Michael A},
  booktitle={ICMC},
  year={2014}
}

% == other ==

@misc{arss,
  title = {The ARSS},
  howpublished = {\url{http://www.arss.sourceforge.net}},
  note = {Accessed: 2019-03-19}
}






